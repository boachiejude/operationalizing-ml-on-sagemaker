{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118fe79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket and prefix\n",
    "bucket = 'solutionudacity'\n",
    "prefix = 'sagemaker/DEMO-data-distribution-types'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import io\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import sys\n",
    "import sagemaker.amazon.common as smac\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211af5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdelt(filename):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket('gdelt-open-data').download_file('events/' + filename, '.gdelt.csv')\n",
    "    df = pd.read_csv('.gdelt.csv', sep='\\t')\n",
    "    header = pd.read_csv('https://www.gdeltproject.org/data/lookups/CSV.header.historical.txt', sep='\\t')\n",
    "    df.columns = header.columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_gdelt('1979.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fe041",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['EventCode', 'NumArticles', 'AvgTone', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor2Geo_Lat', 'Actor2Geo_Long']]\n",
    "data['EventCode'] = data['EventCode'].astype(object)\n",
    "\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=data[column], columns='% observations', normalize='columns'))\n",
    "\n",
    "display(data.describe())\n",
    "hist = data.hist(bins=30, sharey=True, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.crosstab(index=data['EventCode'], columns='count').sort_values(by='count', ascending=False).index[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c26d02",
   "metadata": {},
   "source": [
    "## Similarly doing for other years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(bucket, prefix, channel, file_prefix, X, y):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(buf, X.astype('float32'), y.astype('float32'))\n",
    "    buf.seek(0)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, channel, file_prefix + '.data')).upload_fileobj(buf)\n",
    "\n",
    "def transform_gdelt(df, events=None):\n",
    "    df = df[['AvgTone', 'EventCode', 'NumArticles', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor2Geo_Lat', 'Actor2Geo_Long']]\n",
    "    df['EventCode'] = df['EventCode'].astype(object)\n",
    "    if events is not None:\n",
    "        df = df[np.in1d(df['EventCode'], events)]\n",
    "    return pd.get_dummies(df[((df['Actor1Geo_Lat'] == 0) & (df['Actor1Geo_Long'] == 0) != True) &\n",
    "                                   ((df['Actor2Geo_Lat'] == 0) & (df['Actor2Geo_Long'] == 0) != True)])\n",
    "    \n",
    "def prepare_gdelt(bucket, prefix, file_prefix, events=None, random_state=1729):\n",
    "    df = get_gdelt(file_prefix + '.csv')\n",
    "    model_data = transform_gdelt(df, events)\n",
    "#    train_data, validation_data = np.split(model_data.sample(frac=1, random_state=random_state).as_matrix(), \n",
    "#                                           [int(0.9 * len(model_data))])\n",
    "    train_data, validation_data = np.split(model_data.sample(frac=1, random_state=random_state).values, \n",
    "                                           [int(0.9 * len(model_data))])\n",
    "\n",
    "    write_to_s3(bucket, prefix, 'train', file_prefix, train_data[:, 1:], train_data[:, 0])\n",
    "    write_to_s3(bucket, prefix, 'validation', file_prefix, validation_data[:, 1:], validation_data[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1979, 1984):\n",
    "    prepare_gdelt(bucket, prefix, str(year), events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/linear-learner:latest',\n",
    "              'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:latest',\n",
    "              'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/linear-learner:latest',\n",
    "              'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/linear-learner:latest'}\n",
    "container = containers[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6804477",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_training_params = {\n",
    "    \"RoleArn\": role,\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": container,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 5,\n",
    "        \"InstanceType\": \"ml.c4.2xlarge\",\n",
    "        \"VolumeSizeInGB\": 10\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix)\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/validation/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\"\n",
    "        }\n",
    "\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": \"s3://{}/{}/\".format(bucket, prefix)\n",
    "    },\n",
    "    \"HyperParameters\": {\n",
    "        \"feature_dim\": \"25\",\n",
    "        \"mini_batch_size\": \"500\",\n",
    "        \"predictor_type\": \"regressor\",\n",
    "        \"epochs\": \"2\",\n",
    "        \"num_models\": \"32\",\n",
    "        \"loss\": \"absolute_loss\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 60 * 60\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharded_job = 'DEMO-linear-sharded-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "print(\"Job name is:\", sharded_job)\n",
    "\n",
    "sharded_training_params = copy.deepcopy(common_training_params)\n",
    "sharded_training_params['TrainingJobName'] = sharded_job\n",
    "sharded_training_params['InputDataConfig'][0]['DataSource']['S3DataSource']['S3DataDistributionType'] = 'ShardedByS3Key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a42e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicated_job = 'DEMO-linear-replicated-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "print(\"Job name is:\", replicated_job)\n",
    "\n",
    "replicated_training_params = copy.deepcopy(common_training_params)\n",
    "replicated_training_params['TrainingJobName'] = replicated_job\n",
    "replicated_training_params['InputDataConfig'][0]['DataSource']['S3DataSource']['S3DataDistributionType'] = 'FullyReplicated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ae9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sm = boto3.Session().client('sagemaker')\n",
    "\n",
    "sm.create_training_job(**sharded_training_params)\n",
    "sm.create_training_job(**replicated_training_params)\n",
    "\n",
    "status = sm.describe_training_job(TrainingJobName=replicated_job)['TrainingJobStatus']\n",
    "print(status)\n",
    "sm.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=replicated_job)\n",
    "status = sm.describe_training_job(TrainingJobName=replicated_job)['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)\n",
    "if status == 'Failed':\n",
    "    message = sm.describe_training_job(TrainingJobName=replicated_job)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))\n",
    "    raise Exception('Training job failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc44233",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sharded:', sm.describe_training_job(TrainingJobName=sharded_job)['TrainingJobStatus'])\n",
    "print('Replicated:', sm.describe_training_job(TrainingJobName=replicated_job)['TrainingJobStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19914424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
